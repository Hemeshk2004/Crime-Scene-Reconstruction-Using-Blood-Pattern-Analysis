{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNrIo9PKY3s0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dir = \"/content/drive/MyDrive/proj/valid_0\""
      ],
      "metadata": {
        "id": "iir9FvwXa7DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqwhut_Wa9iu",
        "outputId": "adf53ede-2687-4961-9f4c-f825611adc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 files belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"drop\", \"flow\", \"pool\", \"pattern\", \"swipe\", \"wiping\",\"high\",\"low\",\"medium\"]  # Update based on your dataset\n"
      ],
      "metadata": {
        "id": "1Yiflajfbd0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "\n",
        "# Increase max image pixel limit to prevent DecompressionBombError\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Allows loading truncated/corrupt images\n",
        "\n",
        "def remove_or_resize_large_images(directory, max_size=(1024, 1024)):\n",
        "    for folder in os.listdir(directory):\n",
        "        folder_path = os.path.join(directory, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                try:\n",
        "                    with Image.open(file_path) as img:\n",
        "                        img.load()  # Load image to catch potential errors\n",
        "\n",
        "                        # Convert to RGB (fixes transparency warning)\n",
        "                        if img.mode in (\"P\", \"RGBA\", \"LA\"):\n",
        "                            img = img.convert(\"RGB\")\n",
        "\n",
        "                        # Resize if too large\n",
        "                        if img.size[0] * img.size[1] > 178956970:\n",
        "                            print(f\"⚠️ Resizing large image: {file_path}\")\n",
        "                            img = img.resize(max_size)\n",
        "                            img.save(file_path)\n",
        "\n",
        "                except (IOError, SyntaxError, ValueError, Image.DecompressionBombError) as e:\n",
        "                    print(f\"❌ Removing corrupt/oversized image: {file_path} due to error: {e}\")\n",
        "                    os.remove(file_path)  # Delete the corrupted/oversized file\n",
        "\n",
        "# Run for both train and validation datasets\n",
        "remove_or_resize_large_images(\"/content/drive/MyDrive/train\")\n",
        "remove_or_resize_large_images(\"/content/valid_0\")\n",
        "\n",
        "print(\"✅ Large images resized & corrupt images removed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EsVnh4kjQGn",
        "outputId": "c881a9ea-b87f-4ca7-d218-741e00a8ea59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Resizing large image: /content/valid_0/HighSpatter/highgh_6.jpg\n",
            "⚠️ Resizing large image: /content/valid_0/HighSpatter/highgh_14.jpg\n",
            "✅ Large images resized & corrupt images removed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "train_dir = \"/content/drive/MyDrive/train\"\n",
        "valid_dir = \"/content/valid_0\"\n",
        "\n",
        "# Define image size and batch size\n",
        "IMG_SIZE = (224, 224)  # Standard for ResNet\n",
        "BATCH_SIZE = 32\n"
      ],
      "metadata": {
        "id": "XlpO_yKTfU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load datasets\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aCWb-OLqMe1",
        "outputId": "1b63ab8b-cd4b-4d7c-c00a-b9655ae5bb7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2132 files belonging to 9 classes.\n",
            "Found 8 files belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get class names\n",
        "class_names = train_dataset.class_names\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# Normalize data\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE-_WubCqPIh",
        "outputId": "673427de-8540-489e-a173-d8ae22204200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names: ['Drop', 'Flow', 'Pattern', 'Pool', 'Swipe', 'Wipe', 'highspatter', 'low velocity blood spatter', 'mediumspatter']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "])\n"
      ],
      "metadata": {
        "id": "56BdCi-kqX67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load pre-trained ResNet50V2\n",
        "base_model = tf.keras.applications.ResNet50V2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\"\n",
        ")\n",
        "base_model.trainable = False  # Freeze base layers initially\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91O2nJ1YqeeB",
        "outputId": "e50a9e5b-01e8-48ba-e6cc-bfeb328661b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define model\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)  # No batch norm update during freezing\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "w2km3hJJqgrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "oVncQ4FmqlGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "train_dir = \"/content/drive/MyDrive/train\"\n",
        "valid_dir = \"/content/valid_0\"\n",
        "\n",
        "# Verify that directories exist\n",
        "if not os.path.exists(train_dir) or not os.path.exists(valid_dir):\n",
        "    raise FileNotFoundError(\"❌ Training or Validation directory does not exist!\")\n",
        "\n",
        "# Define image size and batch size\n",
        "IMG_SIZE = (224, 224)  # Standard for ResNet\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Re-load datasets after removing missing files\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Get updated class names\n",
        "class_names = train_dataset.class_names\n",
        "print(f\"✅ Updated Class Names: {class_names}\")\n",
        "\n",
        "# Normalize data\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "# Now try training again\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "print(\"✅ Training started successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qDohsl_vK23",
        "outputId": "1ec3404a-4359-4dd7-896f-240597546895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2132 files belonging to 9 classes.\n",
            "Found 8 files belonging to 9 classes.\n",
            "✅ Updated Class Names: ['Drop', 'Flow', 'Pattern', 'Pool', 'Swipe', 'Wipe', 'highspatter', 'low velocity blood spatter', 'mediumspatter']\n",
            "Epoch 1/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 6s/step - accuracy: 0.2215 - loss: 2.6186 - val_accuracy: 0.2500 - val_loss: 2.2103\n",
            "Epoch 2/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 6s/step - accuracy: 0.5044 - loss: 1.4940 - val_accuracy: 0.1250 - val_loss: 2.4548\n",
            "Epoch 3/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 6s/step - accuracy: 0.6560 - loss: 1.0980 - val_accuracy: 0.1250 - val_loss: 2.7899\n",
            "Epoch 4/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 6s/step - accuracy: 0.7372 - loss: 0.8416 - val_accuracy: 0.1250 - val_loss: 3.2497\n",
            "Epoch 5/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 6s/step - accuracy: 0.7688 - loss: 0.7364 - val_accuracy: 0.1250 - val_loss: 3.6896\n",
            "Epoch 6/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 6s/step - accuracy: 0.7879 - loss: 0.6545 - val_accuracy: 0.1250 - val_loss: 3.8766\n",
            "Epoch 7/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 6s/step - accuracy: 0.8219 - loss: 0.5640 - val_accuracy: 0.1250 - val_loss: 4.1600\n",
            "Epoch 8/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 6s/step - accuracy: 0.8207 - loss: 0.5503 - val_accuracy: 0.1250 - val_loss: 4.4483\n",
            "Epoch 9/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 6s/step - accuracy: 0.8310 - loss: 0.5358 - val_accuracy: 0.1250 - val_loss: 4.7091\n",
            "Epoch 10/10\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 6s/step - accuracy: 0.8593 - loss: 0.4517 - val_accuracy: 0.0000e+00 - val_loss: 4.8907\n",
            "✅ Training started successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/bloodstain_model.keras\")\n",
        "print(\"✅ Model saved successfully in .keras format!\")"
      ],
      "metadata": {
        "id": "sLgxamFfvMWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a382e879-5c94-424b-bcd5-f7e6016e8c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved successfully in .keras format!\n"
          ]
        }
      ]
    }
  ]
}